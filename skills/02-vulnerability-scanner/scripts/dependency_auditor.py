#!/usr/bin/env python3
"""
Dependency Vulnerability Auditor
Scans project dependencies for known CVEs using the OSV database.

Repository: https://github.com/Masriyan/Claude-Code-CyberSecurity-Skill
"""

import argparse
import json
import logging
import os
import re
import sys
import time
from typing import Any, Dict, List, Optional, Tuple

try:
    import requests
except ImportError:
    print("[!] 'requests' module required: pip install requests")
    sys.exit(1)

logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s [%(levelname)s] %(message)s",
    datefmt="%Y-%m-%d %H:%M:%S",
)
logger = logging.getLogger(__name__)

OSV_API_URL = "https://api.osv.dev/v1/query"
OSV_VULN_URL = "https://api.osv.dev/v1/vulns"

SEVERITY_ORDER = {"CRITICAL": 4, "HIGH": 3, "MEDIUM": 2, "LOW": 1, "UNKNOWN": 0}


class DependencyAuditor:
    """Scans project dependencies against vulnerability databases."""

    def __init__(self, severity_filter: Optional[List[str]] = None):
        self.session = requests.Session()
        self.session.headers.update({"Content-Type": "application/json"})
        self.severity_filter = [s.upper() for s in (severity_filter or [])]
        self.findings: List[Dict[str, Any]] = []

    def detect_ecosystem(self, project_dir: str) -> List[Tuple[str, str]]:
        """Detect package ecosystems and their dependency files."""
        detected = []
        file_map = {
            "requirements.txt": "PyPI",
            "Pipfile.lock": "PyPI",
            "pyproject.toml": "PyPI",
            "package.json": "npm",
            "package-lock.json": "npm",
            "yarn.lock": "npm",
            "go.mod": "Go",
            "Cargo.toml": "crates.io",
            "Cargo.lock": "crates.io",
            "Gemfile.lock": "RubyGems",
            "composer.lock": "Packagist",
            "pom.xml": "Maven",
        }

        for filename, ecosystem in file_map.items():
            filepath = os.path.join(project_dir, filename)
            if os.path.exists(filepath):
                detected.append((ecosystem, filepath))
                logger.info("[Detect] Found %s (%s)", filename, ecosystem)

        return detected

    def parse_requirements_txt(self, filepath: str) -> List[Dict[str, str]]:
        """Parse Python requirements.txt."""
        packages = []
        with open(filepath, "r") as f:
            for line in f:
                line = line.strip()
                if not line or line.startswith("#") or line.startswith("-"):
                    continue
                match = re.match(r"^([a-zA-Z0-9_.-]+)\s*([><=!~]+)?\s*([0-9a-zA-Z._*-]+)?", line)
                if match:
                    packages.append({
                        "name": match.group(1),
                        "version": match.group(3) or "unknown",
                        "constraint": match.group(2) or "==",
                    })
        return packages

    def parse_package_json(self, filepath: str) -> List[Dict[str, str]]:
        """Parse npm package.json."""
        packages = []
        with open(filepath, "r") as f:
            data = json.load(f)

        for dep_type in ["dependencies", "devDependencies"]:
            deps = data.get(dep_type, {})
            for name, version in deps.items():
                clean_version = re.sub(r"[\^~>=<]", "", version).strip()
                packages.append({
                    "name": name,
                    "version": clean_version,
                    "constraint": version,
                    "type": dep_type,
                })
        return packages

    def parse_go_mod(self, filepath: str) -> List[Dict[str, str]]:
        """Parse Go go.mod."""
        packages = []
        with open(filepath, "r") as f:
            inside_require = False
            for line in f:
                line = line.strip()
                if line.startswith("require ("):
                    inside_require = True
                    continue
                if line == ")":
                    inside_require = False
                    continue
                if inside_require or line.startswith("require "):
                    parts = line.replace("require ", "").strip().split()
                    if len(parts) >= 2:
                        packages.append({
                            "name": parts[0],
                            "version": parts[1].lstrip("v"),
                        })
        return packages

    def query_osv(self, package_name: str, version: str, ecosystem: str) -> List[Dict]:
        """Query OSV database for vulnerabilities."""
        payload = {
            "version": version,
            "package": {"name": package_name, "ecosystem": ecosystem},
        }
        try:
            response = self.session.post(OSV_API_URL, json=payload, timeout=10)
            if response.status_code == 200:
                data = response.json()
                return data.get("vulns", [])
        except Exception as e:
            logger.debug("[OSV] Query error for %s: %s", package_name, str(e))
        return []

    def get_severity(self, vuln: Dict) -> str:
        """Extract severity from vulnerability data."""
        severity_list = vuln.get("severity", [])
        if severity_list:
            for s in severity_list:
                score_str = s.get("score", "")
                if score_str:
                    try:
                        score = float(score_str.split("/")[0]) if "/" in score_str else float(score_str)
                        if score >= 9.0:
                            return "CRITICAL"
                        elif score >= 7.0:
                            return "HIGH"
                        elif score >= 4.0:
                            return "MEDIUM"
                        else:
                            return "LOW"
                    except ValueError:
                        pass
        db_severity = vuln.get("database_specific", {}).get("severity", "")
        if db_severity:
            return db_severity.upper()
        return "UNKNOWN"

    def audit_packages(
        self, packages: List[Dict], ecosystem: str
    ) -> List[Dict[str, Any]]:
        """Audit a list of packages for vulnerabilities."""
        findings = []
        total = len(packages)

        for i, pkg in enumerate(packages, 1):
            name = pkg["name"]
            version = pkg.get("version", "unknown")
            if version == "unknown":
                continue

            logger.info("[Audit] [%d/%d] Checking %s@%s", i, total, name, version)
            vulns = self.query_osv(name, version, ecosystem)

            for vuln in vulns:
                severity = self.get_severity(vuln)
                if self.severity_filter and severity not in self.severity_filter:
                    continue

                finding = {
                    "package": name,
                    "installed_version": version,
                    "vulnerability_id": vuln.get("id", "N/A"),
                    "aliases": vuln.get("aliases", []),
                    "summary": vuln.get("summary", "No description available"),
                    "severity": severity,
                    "fixed_versions": self._get_fixed_versions(vuln, ecosystem),
                    "references": [
                        ref.get("url", "") for ref in vuln.get("references", [])[:3]
                    ],
                }
                findings.append(finding)
                logger.warning(
                    "[VULN] %s@%s â€” %s (%s)",
                    name, version, vuln.get("id"), severity,
                )

        return findings

    def _get_fixed_versions(self, vuln: Dict, ecosystem: str) -> List[str]:
        """Extract fixed versions from vulnerability data."""
        fixed = []
        for affected in vuln.get("affected", []):
            for rng in affected.get("ranges", []):
                for event in rng.get("events", []):
                    if "fixed" in event:
                        fixed.append(event["fixed"])
        return fixed

    def audit_project(self, project_dir: str) -> Dict[str, Any]:
        """Run full audit on a project directory."""
        logger.info("=" * 60)
        logger.info("Dependency Vulnerability Audit")
        logger.info("Project: %s", project_dir)
        logger.info("=" * 60)

        ecosystems = self.detect_ecosystem(project_dir)
        if not ecosystems:
            logger.error("No dependency files found in %s", project_dir)
            return {"error": "No dependency files found"}

        all_findings = []
        for ecosystem, filepath in ecosystems:
            logger.info("[Parse] Parsing %s", filepath)
            if ecosystem == "PyPI":
                packages = self.parse_requirements_txt(filepath)
            elif ecosystem == "npm":
                packages = self.parse_package_json(filepath)
            elif ecosystem == "Go":
                packages = self.parse_go_mod(filepath)
            else:
                logger.warning("[Parse] Unsupported parser for %s", ecosystem)
                continue

            logger.info("[Parse] Found %d packages in %s", len(packages), os.path.basename(filepath))
            findings = self.audit_packages(packages, ecosystem)
            all_findings.extend(findings)

        # Sort by severity
        all_findings.sort(
            key=lambda x: SEVERITY_ORDER.get(x["severity"], 0), reverse=True
        )

        results = {
            "project_directory": project_dir,
            "total_packages_scanned": sum(
                len(self.parse_requirements_txt(fp)) if eco == "PyPI" else 0
                for eco, fp in ecosystems
            ),
            "total_vulnerabilities": len(all_findings),
            "severity_counts": {
                sev: sum(1 for f in all_findings if f["severity"] == sev)
                for sev in ["CRITICAL", "HIGH", "MEDIUM", "LOW", "UNKNOWN"]
            },
            "findings": all_findings,
            "timestamp": time.strftime("%Y-%m-%dT%H:%M:%SZ", time.gmtime()),
        }

        logger.info("=" * 60)
        logger.info("Audit complete: %d vulnerabilities found", len(all_findings))
        for sev in ["CRITICAL", "HIGH", "MEDIUM", "LOW"]:
            count = results["severity_counts"].get(sev, 0)
            if count > 0:
                logger.info("  %s: %d", sev, count)
        logger.info("=" * 60)

        return results


def main():
    parser = argparse.ArgumentParser(
        description="Dependency Vulnerability Auditor",
        epilog="https://github.com/Masriyan/Claude-Code-CyberSecurity-Skill",
    )
    parser.add_argument(
        "--project-dir", "-p", required=True, help="Project directory to audit"
    )
    parser.add_argument(
        "--output", "-o", help="Output file path (JSON)"
    )
    parser.add_argument(
        "--format", "-f", choices=["json", "text"], default="json", help="Output format"
    )
    parser.add_argument(
        "--severity", "-s", help="Filter by severity (comma-separated: critical,high,medium,low)"
    )
    parser.add_argument("--verbose", "-v", action="store_true")
    args = parser.parse_args()

    if args.verbose:
        logging.getLogger().setLevel(logging.DEBUG)

    severity_filter = args.severity.split(",") if args.severity else None
    auditor = DependencyAuditor(severity_filter=severity_filter)
    results = auditor.audit_project(args.project_dir)

    if args.output:
        with open(args.output, "w") as f:
            json.dump(results, f, indent=2)
        logger.info("Results saved to %s", args.output)
    else:
        print(json.dumps(results, indent=2))


if __name__ == "__main__":
    main()
